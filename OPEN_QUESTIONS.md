# Open Questions — Taxonomy Experiment

- **Generated by:** Claude Opus 4.6
- **Timestamp:** 2026-02-14
- **Context:** Experiment deriving a hierarchical taxonomy from `scenes/` directory only

---

## Open Questions

### OQ-1: Can the system detect when its derived taxonomy no longer matches its declared vision?

- **Raised by:** Dan
- **Date:** 2026-02-14
- **Status:** Open
- **Why it matters:** The North Star and Design Charter exist as explicit governance anchors, but if nothing checks the graph against them, they become decorative rather than functional. The system could silently regress into a note-taking system — the exact outcome the Design Charter prohibits.

### OQ-2: Which KPI should anchor the vision-alignment audit first?

- **Raised by:** Dan
- **Date:** 2026-02-15
- **Status:** Resolved
- **Resolution:** Start with `principle_linked_artifact_pct` as the first anchor KPI.
- **Decision detail:** Measure `% of non-trivial session artifacts with >=1 canonical principle link`.
- **Initial targets:** pass `>=75%`, stretch `>=85%`.

### OQ-3: Should hyperfast agent execution require a human-approval gate when `next_steps` exceeds 3 items?

- **Raised by:** Dan
- **Date:** 2026-02-15
- **Status:** Open
- **Why it matters:** Could prevent scope spill and keep delegated loops aligned with hyperfast constraints.

### OQ-4: How should multi-agent coordination be controlled (audit agent vs execution agent) to avoid scene/file contention?

- **Raised by:** Dan
- **Date:** 2026-02-15
- **Status:** Open
- **Why it matters:** Without locking/ownership rules, concurrent agents can create non-deterministic edits.

---

## Journal

### 2026-02-14 — Claude Opus 4.6 — Initial analysis

**Short answer: Not yet. The system has drift detection, but it's all structural, not vision-aligned.**

#### What the system CAN detect (structural drift)

- **Spec drift tests** — verify required sections present, filename regex conformance, deterministic rendering, repeat-run stability. These check *"is this spec well-formed?"*, not *"is this spec serving the North Star?"*
- **Prompt lineage drift tests** — verify deterministic materialization (same base + same deltas = byte-identical output). Checks replay fidelity, not semantic direction.
- **Session index rebuild rules** — detect when indexes fall out of sync with artifact directories. Structural bookkeeping.
- **Kalshi phase history `drift_signals`** — tracks regression, oscillation, stagnation within a single project's phase progression. Closest thing to semantic drift detection, but scoped to one project and manually authored.
- **Robustness gate directives** — perturbation tiers, invariance requirements, promotion criteria. Designed for pipeline/model robustness, not taxonomy-vision coherence.

#### What the system CANNOT detect

Whether the taxonomy as a whole is drifting from the declared vision:

> *"ideas become structured artifacts, artifacts become connected meaning, and meaning becomes executable reasoning"*

No scene defines a mechanism that periodically compares the graph's actual content distribution, edge density, or conceptual coverage against the North Star or Design Charter. The system can tell you if a spec is malformed, but not if the entire knowledge graph is quietly becoming the "note-taking system" the Design Charter explicitly says it is not.

#### The specific gap

There is no **vision-alignment audit** — something that would ask:

1. Are new nodes compounding into connected meaning, or accumulating as isolated artifacts?
2. Is "executable reasoning" actually emerging (agents traversing the graph), or is the graph inert?
3. Are principles governing pattern selection, or are patterns proliferating without principled constraint?
4. What percentage of the graph is reachable from the North Star via typed edges vs. orphaned?

#### Closest existing precedent

The `drift_signals` object in `kalshi_phase_history.scene.json` (fields: `regression`, `oscillation`, `stagnation`) is the nearest structural analog. It would need to be generalized to the whole taxonomy and grounded against the declared vision rather than a single project's phase sequence.

### 2026-02-14 — Codex — ASLB run blocked

- **Event:** Tried to execute `python3 scripts/run_aslb.py --model gpt-4.1 --context-file README.md --run-slug 2026-02-14-drift-audit`.
- **Result:** Script aborted with `API key is required unless running with --dry-run`.
- **Implication:** Cannot produce a real ASLB benchmark snapshot until `OPENAI_API_KEY` (or compatible `--api-key`) is available.
- **Next action:** Add a valid key and rerun the command above to capture artifacts under `operations/aslb_runs/2026-02-14-drift-audit/`.

### 2026-02-15 — Codex — Vision-alignment KPI anchor selected

- **Question resolved:** OQ-2 (`Which KPI should anchor the vision-alignment audit first?`)
- **Selected KPI:** `principle_linked_artifact_pct`
- **Rationale:** Most directly aligned with principle-grounded agent resumability and computable immediately without requiring full graph ingest maturity.
- **Targets:** pass `>=75%`, stretch `>=85%` for non-trivial session artifacts.
